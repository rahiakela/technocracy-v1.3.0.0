
function encodeHTML(str) {
    if (!str) {
        return '';
    }
    const html = str.replace(/[^a-z0-9A-Z ]/g, c => {
        return '&#' + c.charCodeAt() + ';';
    });
    return html;
}

// ref-https://gist.github.com/CatTail/4174511
function decodeHTML(str) {
    if (str) {
        return str.replace(/&#(\d+);/g, (match, dec) => {
            return String.fromCharCode(dec);
        });
    }
    return;
}

const rawHTML = `
<blockquote><strong style="color: rgba(0, 0, 0, 0.84);"><em>Perceptron is a single layer neural network</em></strong><em style="color: rgba(0, 0, 0, 0.84);">&nbsp;and a mult
i-layer perceptron is called Neural Networks.</em></blockquote><p>Perceptron is a linear classifier (binary). Also, it is used in supervised learning. It helps to classify the g
iven input data. But how the heck it works&nbsp;?</p><p>A normal neural network looks like this as we all know</p><p><img src="https://storage.googleapis.com/technocracy-157812.appspot.com/technocracy/images/blogs/
59945b98d3a8604780c6e4a2/eEKb2RxREV6-MtLz2DNWFQ-min.gif"></p><p><br></p><p>As you can see it has multiple layers.</p><p>The perceptron consists of 4 parts&nbsp;.</p><ol><li>Inpu
t values or One input layer</li><li>Weights and Bias</li><li>Net sum</li><li><span style="background-color: transparent; color: inherit;">Activation Function</span></li></ol><bl
ockquote><em style="color: rgba(0, 0, 0, 0.84);">FYI: The Neural Networks work the same way as the perceptron. So, if you want to know how neural network works, learn how percep
tron works.﻿</em></blockquote><p><img src="https://storage.googleapis.com/technocracy-157812.appspot.com/technocracy/images/blogs/59945b98d3a8604780c6e4a2/n6sJ4yZQzwKL9wnF5wnVNg.png"></p><h4>But how does it&nbsp;wo
rk?</h4><p>The perceptron works on these simple steps</p><p>a. All the inputs&nbsp;<strong><em>x</em></strong>&nbsp;are multiplied with their weights&nbsp;<strong><em>w</em></st
rong>. Let’s call it&nbsp;<strong><em>k.</em></strong></p><p><img src="https://storage.googleapis.com/technocracy-157812.appspot.com/technocracy/images/blogs/59945b98d3a8604780c6e4a2/1__Zy1C83cnmYUdETCeQrOgA.png"><
/p><p><span style="color: rgba(0, 0, 0, 0.84);">b.&nbsp;</span><strong style="color: rgba(0, 0, 0, 0.84);"><em>Add</em></strong><span style="color: rgba(0, 0, 0, 0.84);">&nbsp;a
ll the multiplied values and call them&nbsp;</span><strong style="color: rgba(0, 0, 0, 0.84);"><em>Weighted Sum.</em></strong></p><p><img src="https://tecknocracy.s3.amazonaws.c
om/images/blogs/59945b98d3a8604780c6e4a2/1_xFd9VQnUM1H0kiCENsoYxg.gif"></p><p><span style="color: rgba(0, 0, 0, 0.84);">c.&nbsp;</span><strong style="color: rgba(0, 0, 0, 0.84);
"><em>Apply</em></strong><span style="color: rgba(0, 0, 0, 0.84);">&nbsp;that weighted sum to the correct&nbsp;</span><strong style="color: inherit;"><em>Activation Function</em
></strong><span style="color: inherit;">.</span></p><p><span style="color: rgba(0, 0, 0, 0.84);">For Example&nbsp;: Unit Step Activation Function.</span></p><p><img src="https:/
/tecknocracy.s3.amazonaws.com/images/blogs/59945b98d3a8604780c6e4a2/1_0iOzeMS3s-3LTU9hYH9ryg.png"></p><p><br></p><h4>Why do we need Weights and&nbsp;Bias?</h4><blockquote><em>We
ights&nbsp;shows the strength of the particular node.</em></blockquote><blockquote><em>A bias&nbsp;value allows you to shift the activation function curve up or&nbsp;down.</em><
/blockquote><p><img src="https://storage.googleapis.com/technocracy-157812.appspot.com/technocracy/images/blogs/59945b98d3a8604780c6e4a2/1_ztXU57QEETPHGXczHrSWSA.gif"></p><p><br></p><h4>Why do we need Activation Fu
nction?</h4><blockquote><em>In short,&nbsp;the activation functions are used to map the input between the required values like (0, 1) or (-1,&nbsp;1).</em></blockquote><p><span
style="color: rgba(0, 0, 0, 0.84);">For a better explanation go to my previous story&nbsp;</span><a href="https://www.tecknocracy.com/blog/5c05466b6758916e3095fa62" target="_bla
nk" style="color: inherit;">Activation Functions&nbsp;: Neural Networks</a><span style="color: rgba(0, 0, 0, 0.84);">.</span></p><h4>Where we use Perceptron?</h4><blockquote><em
>Perceptron is usually used to classify the data into two parts. Therefore, it is also known as a&nbsp;</em><em style="color: inherit; background-color: transparent;">Linear Bin
ary Classifier</em><em>.</em></blockquote><p><img src="https://storage.googleapis.com/technocracy-157812.appspot.com/technocracy/images/blogs/59945b98d3a8604780c6e4a2/1_xsR57_PO8U7PB_ItLslLmA.png"></p><p>Any commen
ts or if you have any question,&nbsp;<strong>write it in the comment.</strong></p><p><strong>Clap it! Share it! Follow Me!</strong></p><p>Happy to be helpful. kudos…..</p>

`;
console.log(encodeHTML(rawHTML));

const encodedHTML = `
    &#60;blockquote&#62;&#60;strong style&#61;&#34;color&#58; rgba&#40;0&#44; 0&#44; 0&#44; 0&#46;84&#41;&#59;&#34;&#62;&#60;em&#62;Perceptron is a single layer neural network&#60;&#47;em&#62;&#60;&#47;strong&#62;&#60;em style&#61;&#34;color&#58; rgba&#40;0&#44; 0&#44; 0&#44; 0&#46;84&#41;&#59;&#34;&#62;&#38;nbsp&#59;and a multi&#45;layer perceptron is called Neural Networks&#46;&#60;&#47;em&#62;&#60;&#47;blockquote&#62;&#60;p&#62;Perceptron is a linear classifier &#40;binary&#41;&#46; Also&#44; it is used in supervised learning&#46; It helps to classify the given input data&#46; But how the heck it works&#38;nbsp&#59;&#63;&#60;&#47;p&#62;&#60;p&#62;A normal neural network looks like this as we all know&#60;&#47;p&#62;&#60;p&#62;&#60;img src&#61;&#34;https&#58;&#47;&#47;tecknocracy&#46;s3&#46;amazonaws&#46;com&#47;images&#47;blogs&#47;59945b98d3a8604780c6e4a2&#47;eEKb2RxREV6&#45;MtLz2DNWFQ&#45;min&#46;gif&#34;&#62;&#60;&#47;p&#62;&#60;p&#62;&#60;br&#62;&#60;&#47;p&#62;&#60;p&#62;As you can see it has multiple layers&#46;&#60;&#47;p&#62;&#60;p&#62;The perceptron consists of 4 parts&#38;nbsp&#59;&#46;&#60;&#47;p&#62;&#60;ol&#62;&#60;li&#62;Input values or One input layer&#60;&#47;li&#62;&#60;li&#62;Weights and Bias&#60;&#47;li&#62;&#60;li&#62;Net sum&#60;&#47;li&#62;&#60;li&#62;&#60;span style&#61;&#34;background&#45;color&#58; transparent&#59; color&#58; inherit&#59;&#34;&#62;Activation Function&#60;&#47;span&#62;&#60;&#47;li&#62;&#60;&#47;ol&#62;&#60;blockquote&#62;&#60;em style&#61;&#34;color&#58; rgba&#40;0&#44; 0&#44; 0&#44; 0&#46;84&#41;&#59;&#34;&#62;FYI&#58; The Neural Networks work the same way as the perceptron&#46; So&#44; if you want to know how neural network works&#44; learn how perceptron works&#46;&#65279;&#60;&#47;em&#62;&#60;&#47;blockquote&#62;&#60;p&#62;&#60;img src&#61;&#34;https&#58;&#47;&#47;tecknocracy&#46;s3&#46;amazonaws&#46;com&#47;images&#47;blogs&#47;59945b98d3a8604780c6e4a2&#47;n6sJ4yZQzwKL9wnF5wnVNg&#46;png&#34;&#62;&#60;&#47;p&#62;&#60;h4&#62;But how does it&#38;nbsp&#59;work&#63;&#60;&#47;h4&#62;&#60;p&#62;The perceptron works on these simple steps&#60;&#47;p&#62;&#60;p&#62;a&#46; All the inputs&#38;nbsp&#59;&#60;strong&#62;&#60;em&#62;x&#60;&#47;em&#62;&#60;&#47;strong&#62;&#38;nbsp&#59;are multiplied with their weights&#38;nbsp&#59;&#60;strong&#62;&#60;em&#62;w&#60;&#47;em&#62;&#60;&#47;strong&#62;&#46; Let&#8217;s call it&#38;nbsp&#59;&#60;strong&#62;&#60;em&#62;k&#46;&#60;&#47;em&#62;&#60;&#47;strong&#62;&#60;&#47;p&#62;&#60;p&#62;&#60;img src&#61;&#34;https&#58;&#47;&#47;tecknocracy&#46;s3&#46;amazonaws&#46;com&#47;images&#47;blogs&#47;59945b98d3a8604780c6e4a2&#47;1&#95;&#95;Zy1C83cnmYUdETCeQrOgA&#46;png&#34;&#62;&#60;&#47;p&#62;&#60;p&#62;&#60;span style&#61;&#34;color&#58; rgba&#40;0&#44; 0&#44; 0&#44; 0&#46;84&#41;&#59;&#34;&#62;b&#46;&#38;nbsp&#59;&#60;&#47;span&#62;&#60;strong style&#61;&#34;color&#58; rgba&#40;0&#44; 0&#44; 0&#44; 0&#46;84&#41;&#59;&#34;&#62;&#60;em&#62;Add&#60;&#47;em&#62;&#60;&#47;strong&#62;&#60;span style&#61;&#34;color&#58; rgba&#40;0&#44; 0&#44; 0&#44; 0&#46;84&#41;&#59;&#34;&#62;&#38;nbsp&#59;all the multiplied values and call them&#38;nbsp&#59;&#60;&#47;span&#62;&#60;strong style&#61;&#34;color&#58; rgba&#40;0&#44; 0&#44; 0&#44; 0&#46;84&#41;&#59;&#34;&#62;&#60;em&#62;Weighted Sum&#46;&#60;&#47;em&#62;&#60;&#47;strong&#62;&#60;&#47;p&#62;&#60;p&#62;&#60;img src&#61;&#34;https&#58;&#47;&#47;tecknocracy&#46;s3&#46;amazonaws&#46;com&#47;images&#47;blogs&#47;59945b98d3a8604780c6e4a2&#47;1&#95;xFd9VQnUM1H0kiCENsoYxg&#46;gif&#34;&#62;&#60;&#47;p&#62;&#60;p&#62;&#60;span style&#61;&#34;color&#58; rgba&#40;0&#44; 0&#44; 0&#44; 0&#46;84&#41;&#59;&#34;&#62;c&#46;&#38;nbsp&#59;&#60;&#47;span&#62;&#60;strong style&#61;&#34;color&#58; rgba&#40;0&#44; 0&#44; 0&#44; 0&#46;84&#41;&#59;&#34;&#62;&#60;em&#62;Apply&#60;&#47;em&#62;&#60;&#47;strong&#62;&#60;span style&#61;&#34;color&#58; rgba&#40;0&#44; 0&#44; 0&#44; 0&#46;84&#41;&#59;&#34;&#62;&#38;nbsp&#59;that weighted sum to the correct&#38;nbsp&#59;&#60;&#47;span&#62;&#60;strong style&#61;&#34;color&#58; inherit&#59;&#34;&#62;&#60;em&#62;Activation Function&#60;&#47;em&#62;&#60;&#47;strong&#62;&#60;span style&#61;&#34;color&#58; inherit&#59;&#34;&#62;&#46;&#60;&#47;span&#62;&#60;&#47;p&#62;&#60;p&#62;&#60;span style&#61;&#34;color&#58; rgba&#40;0&#44; 0&#44; 0&#44; 0&#46;84&#41;&#59;&#34;&#62;For Example&#38;nbsp&#59;&#58; Unit Step Activation Function&#46;&#60;&#47;span&#62;&#60;&#47;p&#62;&#60;p&#62;&#60;img src&#61;&#34;https&#58;&#47;&#47;tecknocracy&#46;s3&#46;amazonaws&#46;com&#47;images&#47;blogs&#47;59945b98d3a8604780c6e4a2&#47;1&#95;0iOzeMS3s&#45;3LTU9hYH9ryg&#46;png&#34;&#62;&#60;&#47;p&#62;&#60;p&#62;&#60;br&#62;&#60;&#47;p&#62;&#60;h4&#62;Why do we need Weights and&#38;nbsp&#59;Bias&#63;&#60;&#47;h4&#62;&#60;blockquote&#62;&#60;em&#62;Weights&#38;nbsp&#59;shows the strength of the particular node&#46;&#60;&#47;em&#62;&#60;&#47;blockquote&#62;&#60;blockquote&#62;&#60;em&#62;A bias&#38;nbsp&#59;value allows you to shift the activation function curve up or&#38;nbsp&#59;down&#46;&#60;&#47;em&#62;&#60;&#47;blockquote&#62;&#60;p&#62;&#60;img src&#61;&#34;https&#58;&#47;&#47;tecknocracy&#46;s3&#46;amazonaws&#46;com&#47;images&#47;blogs&#47;59945b98d3a8604780c6e4a2&#47;1&#95;ztXU57QEETPHGXczHrSWSA&#46;gif&#34;&#62;&#60;&#47;p&#62;&#60;p&#62;&#60;br&#62;&#60;&#47;p&#62;&#60;h4&#62;Why do we need Activation Function&#63;&#60;&#47;h4&#62;&#60;blockquote&#62;&#60;em&#62;In short&#44;&#38;nbsp&#59;the activation functions are used to map the input between the required values like &#40;0&#44; 1&#41; or &#40;&#45;1&#44;&#38;nbsp&#59;1&#41;&#46;&#60;&#47;em&#62;&#60;&#47;blockquote&#62;&#60;p&#62;&#60;span style&#61;&#34;color&#58; rgba&#40;0&#44; 0&#44; 0&#44; 0&#46;84&#41;&#59;&#34;&#62;For a better explanation go to my previous story&#38;nbsp&#59;&#60;&#47;span&#62;&#60;a href&#61;&#34;https&#58;&#47;&#47;www&#46;tecknocracy&#46;com&#47;blog&#47;5c05466b6758916e3095fa62&#34; target&#61;&#34;&#95;blank&#34; style&#61;&#34;color&#58; inherit&#59;&#34;&#62;Activation Functions&#38;nbsp&#59;&#58; Neural Networks&#60;&#47;a&#62;&#60;span style&#61;&#34;color&#58; rgba&#40;0&#44; 0&#44; 0&#44; 0&#46;84&#41;&#59;&#34;&#62;&#46;&#60;&#47;span&#62;&#60;&#47;p&#62;&#60;h4&#62;Where we use Perceptron&#63;&#60;&#47;h4&#62;&#60;blockquote&#62;&#60;em&#62;Perceptron is usually used to classify the data into two parts&#46; Therefore&#44; it is also known as a&#38;nbsp&#59;&#60;&#47;em&#62;&#60;em style&#61;&#34;color&#58; inherit&#59; background&#45;color&#58; transparent&#59;&#34;&#62;Linear Binary Classifier&#60;&#47;em&#62;&#60;em&#62;&#46;&#60;&#47;em&#62;&#60;&#47;blockquote&#62;&#60;p&#62;&#60;img src&#61;&#34;https&#58;&#47;&#47;tecknocracy&#46;s3&#46;amazonaws&#46;com&#47;images&#47;blogs&#47;59945b98d3a8604780c6e4a2&#47;1&#95;xsR57&#95;PO8U7PB&#95;ItLslLmA&#46;png&#34;&#62;&#60;&#47;p&#62;&#60;p&#62;Any comments or if you have any question&#44;&#38;nbsp&#59;&#60;strong&#62;write it in the comment&#46;&#60;&#47;strong&#62;&#60;&#47;p&#62;&#60;p&#62;&#60;strong&#62;Clap it&#33; Share it&#33; Follow Me&#33;&#60;&#47;strong&#62;&#60;&#47;p&#62;&#60;p&#62;Happy to be helpful&#46; kudos&#8230;&#46;&#46;&#60;&#47;p&#62;
`;

// console.log(decodeHTML(encodedHTML));